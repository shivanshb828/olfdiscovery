{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load and Preprocess Data\n",
    "# ---------------------------\n",
    "file_path = 'NEW_smilesforcompounds.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Convert the DataFrame column to a list of SMILES strings\n",
    "smiles_list = data[0].tolist()\n",
    "\n",
    "# 2. Generate Morgan Fingerprints\n",
    "# -------------------------------\n",
    "def generate_morgan_fingerprints(smiles_list, radius=2, n_bits=2048):\n",
    "    generator = rdFingerprintGenerator.GetMorganGenerator(radius=radius, fpSize=n_bits)\n",
    "    fingerprints = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            fingerprint = generator.GetFingerprint(mol)\n",
    "            # Convert the fingerprint to a list\n",
    "            fingerprints.append(list(fingerprint))\n",
    "        else:\n",
    "            fingerprints.append([None] * n_bits)\n",
    "    return fingerprints\n",
    "\n",
    "# Generate fingerprints with specified settings\n",
    "radius = 2  # ECFP4 corresponds to a radius of 2\n",
    "n_bits = 2048  # Size of the fingerprint\n",
    "fingerprints = generate_morgan_fingerprints(smiles_list, radius=radius, n_bits=n_bits)\n",
    "\n",
    "# Convert fingerprints to DataFrame\n",
    "fingerprints_df = pd.DataFrame(fingerprints)\n",
    "\n",
    "# 3. Label Data\n",
    "# -------------\n",
    "# Assuming binary labels for bioactivity (1 for active, 0 for inactive)\n",
    "labels = [1 for i in range(112)] + [0 for i in range(112)]  # Adjust this according to your dataset\n",
    "fingerprints_df['Bioactivity'] = labels\n",
    "\n",
    "# 4. Train-Test Split\n",
    "# -------------------\n",
    "X = fingerprints_df.drop(columns=['Bioactivity'])  # Features\n",
    "y = fingerprints_df['Bioactivity']  # Labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Hyperparameter Tuning with GridSearchCV\n",
    "# ------------------------------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best model and hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# 6. Cross-Validation on the Best Model\n",
    "# -------------------------------------\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Average Cross-Validation Score: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# 7. Evaluate the Best Model on the Test Set\n",
    "# ------------------------------------------\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "test_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nTest Set Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Set F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test Set AUC-ROC: {test_auc:.4f}\")\n",
    "\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 8. Feature Importance\n",
    "# ---------------------\n",
    "importances = best_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the top 10 feature rankings\n",
    "print(\"\\nTop 10 Feature Importances:\")\n",
    "for i in range(10):\n",
    "    print(f\"{i + 1}. Feature {indices[i]} ({importances[indices[i]]:.4f})\")\n",
    "\n",
    "# 9. Optionally Save Fingerprints and Labels to a CSV\n",
    "# ---------------------------------------------------\n",
    "fingerprints_df.to_csv(\"morgan_fingerprints_with_butt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 2094\n",
      "Number of testing graphs: 677\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_smiles\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load and Preprocess Data\n",
    "# ---------------------------\n",
    "def load_data(file_path, label):\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    smiles_list = data[0].tolist()\n",
    "    return [(smiles, label) for smiles in smiles_list]\n",
    "\n",
    "pos_train = load_data('model_data/pos_train.csv', 1)\n",
    "neg_train = load_data('model_data/neg_train.csv', 0)\n",
    "pos_test = load_data('model_data/pos_test.csv', 1)\n",
    "neg_test = load_data('model_data/neg_test.csv', 0)\n",
    "\n",
    "train_data = pos_train + neg_train\n",
    "test_data = pos_test + neg_test\n",
    "\n",
    "# 2. Generate Conformers\n",
    "def generate_conformers(smiles, num_conformers=5):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    mol = Chem.AddHs(mol)  # Add hydrogens to the molecule\n",
    "    AllChem.EmbedMultipleConfs(mol, numConfs=num_conformers, randomSeed=42)\n",
    "    return mol\n",
    "\n",
    "# 3. Convert Conformers to Graphs\n",
    "def conformers_to_graphs(mol):\n",
    "    graphs = []\n",
    "    for conf in mol.GetConformers():\n",
    "        mol.SetProp('_Name', str(conf.GetId()))  # Set the conformer ID as its name\n",
    "        graph = from_smiles(Chem.MolToSmiles(mol))\n",
    "        if graph is not None:\n",
    "            graphs.append(graph)\n",
    "    return graphs\n",
    "\n",
    "# 4. Generate Data from SMILES with Conformers\n",
    "def create_graph_data(data):\n",
    "    graph_data_list = []\n",
    "    for smiles, label in data:\n",
    "        mol = generate_conformers(smiles)\n",
    "        conformer_graphs = conformers_to_graphs(mol)\n",
    "        for graph in conformer_graphs:\n",
    "            graph.y = torch.tensor([label], dtype=torch.float)  # Ensure labels are of float type\n",
    "            graph_data_list.append(graph)\n",
    "    return graph_data_list\n",
    "\n",
    "# Create graph data for training and testing sets\n",
    "train_graphs = create_graph_data(train_data)\n",
    "test_graphs = create_graph_data(test_data)\n",
    "\n",
    "# 5. Output Information\n",
    "print(f\"Number of training graphs: {len(train_graphs)}\")\n",
    "print(f\"Number of testing graphs: {len(test_graphs)}\")\n",
    "\n",
    "# Optionally: Combine the datasets if further preprocessing or shuffling is needed\n",
    "# all_graphs = train_graphs + test_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivanshbansal/miniconda3/envs/myenv/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True) \n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8818\n",
      "Test F1 Score: 0.6000\n",
      "Test AUC-ROC: 0.7143\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      1.00      0.93       537\n",
      "         1.0       1.00      0.43      0.60       140\n",
      "\n",
      "    accuracy                           0.88       677\n",
      "   macro avg       0.94      0.71      0.77       677\n",
      "weighted avg       0.90      0.88      0.86       677\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[537   0]\n",
      " [ 80  60]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 6. Define GNN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels=9, out_channels=64)  # Adjust `in_channels` based on your input node features\n",
    "        self.conv2 = GCNConv(in_channels=64, out_channels=32)\n",
    "        self.fc1 = torch.nn.Linear(32, 16)  # The input should match the `out_channels` of the last GCNConv layer\n",
    "        self.fc2 = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x.float(), data.edge_index  # Ensure node features are of float type\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = torch_geometric.nn.global_mean_pool(x, data.batch)  # Global Pooling\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# 7. Train the Model\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy(output.view(-1), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 8. Evaluate the Model\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(data)\n",
    "            preds = (output.view(-1) > 0.5).float()\n",
    "        y_true.extend(data.y.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "    return y_true, y_pred\n",
    "\n",
    "# 9. Main Training Loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    train(model, train_loader, optimizer)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_true_test, y_pred_test = evaluate(model, test_loader)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_true_test, np.round(y_pred_test))\n",
    "test_f1 = f1_score(y_true_test, np.round(y_pred_test))\n",
    "test_auc = roc_auc_score(y_true_test, y_pred_test)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test AUC-ROC: {test_auc:.4f}\")\n",
    "\n",
    "# 10. Print Classification Report and Confusion Matrix\n",
    "# ----------------------------------------------------\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_test, np.round(y_pred_test)))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true_test, np.round(y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dgl xgboost lightgbm catboost keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import from_smiles\n",
    "from tensorflow.keras import layers, models  # Keras models for MLP and RNN\n",
    "\n",
    "# 1. Load and Preprocess Data\n",
    "file_path = 'NEW_smilesforcompounds.csv'\n",
    "data = pd.read_csv(file_path, header=None)\n",
    "smiles_list = data[0].tolist()\n",
    "labels = [1] * 112 + [0] * 112  # Update according to your dataset\n",
    "\n",
    "# 2. Generate MACCS Fingerprints\n",
    "def generate_maccs_fingerprints(smiles_list):\n",
    "    fingerprints = []\n",
    "    for smi in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "        fingerprints.append(np.array(fp))\n",
    "    return pd.DataFrame(fingerprints)\n",
    "\n",
    "fingerprints_df = generate_maccs_fingerprints(smiles_list)\n",
    "fingerprints_df['Bioactivity'] = labels\n",
    "\n",
    "# Save fingerprints to a CSV file\n",
    "fingerprints_df.to_csv('maccs_fingerprints.csv', index=False)\n",
    "\n",
    "X = fingerprints_df.drop(columns=['Bioactivity'])\n",
    "y = fingerprints_df['Bioactivity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Define and Train Traditional ML Models\n",
    "ml_models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "}\n",
    "\n",
    "train_accuracies = {}\n",
    "test_accuracies = {}\n",
    "\n",
    "for name, model in ml_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracies[name] = model.score(X_train, y_train)\n",
    "    test_accuracies[name] = model.score(X_test, y_test)\n",
    "\n",
    "# 4. Define and Train Neural Network Models\n",
    "# MLP Model\n",
    "def create_mlp(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "mlp_model = create_mlp(X_train.shape[1])\n",
    "mlp_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "train_accuracies[\"MLP\"] = mlp_model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_accuracies[\"MLP\"] = mlp_model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "\n",
    "# RNN Model (using LSTM)\n",
    "def create_rnn(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(input_dim=input_shape, output_dim=128),\n",
    "        layers.LSTM(128, return_sequences=True),\n",
    "        layers.LSTM(64),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "rnn_model = create_rnn(X_train.shape[1])\n",
    "rnn_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "train_accuracies[\"RNN\"] = rnn_model.evaluate(X_train, y_train, verbose=0)[1]\n",
    "test_accuracies[\"RNN\"] = rnn_model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "\n",
    "# 5. Define the GNN Model using PyTorch Geometric\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels=9, out_channels=64)\n",
    "        self.conv2 = GCNConv(in_channels=64, out_channels=32)\n",
    "        self.fc1 = torch.nn.Linear(32, 16)\n",
    "        self.fc2 = torch.nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x.float(), data.edge_index  # Ensure x is Float\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = torch_geometric.nn.global_mean_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# 6. Train and Evaluate the GNN Model\n",
    "def smiles_to_graph(smiles_list):\n",
    "    graphs = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        graph = from_smiles(smiles)\n",
    "        if graph:\n",
    "            graphs.append(graph)\n",
    "    return graphs\n",
    "\n",
    "graphs = smiles_to_graph(smiles_list)\n",
    "for i, graph in enumerate(graphs):\n",
    "    graph.y = torch.tensor([labels[i]], dtype=torch.float)\n",
    "\n",
    "train_graphs, test_graphs = train_test_split(graphs, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "def train_model(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    for epoch in range(20):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = loss_fn(output.view(-1), batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(loader)}')\n",
    "\n",
    "train_model(model, train_loader, optimizer, loss_fn)\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch)\n",
    "            y_true.extend(batch.y.cpu().numpy())\n",
    "            y_pred.extend(output.view(-1).cpu().numpy())\n",
    "    return y_true, y_pred\n",
    "\n",
    "y_true_train, y_pred_train = evaluate_model(model, train_loader)\n",
    "y_true_test, y_pred_test = evaluate_model(model, test_loader)\n",
    "\n",
    "train_accuracy = accuracy_score(y_true_train, np.round(y_pred_train))\n",
    "test_accuracy = accuracy_score(y_true_test, np.round(y_pred_test))\n",
    "train_accuracies[\"GNN\"] = train_accuracy\n",
    "test_accuracies[\"GNN\"] = test_accuracy\n",
    "\n",
    "# 7. Plot Accuracies\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.barh(list(test_accuracies.keys()), list(test_accuracies.values()), color='lightgreen')\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_title('Model Test Accuracies')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
